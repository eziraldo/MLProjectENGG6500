{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import time\n",
    "import sklearn\n",
    "from sklearn import preprocessing, cluster\n",
    "import os\n",
    "# import cv2\n",
    "\n",
    "feature_names = ['name', 'order', 'hazType', 'meanXdist', 'meanYdist', 'meanAngle', 'meanSLdist', 'meanXspeed', 'meanYspeed', 'medianXdist', \n",
    "          'medianYdist', 'medianAngle', 'medianSLdist', 'medianXspeed', 'medianYspeed', 'stdXdist', 'stdYdist', 'stdAngle', \n",
    "          'stdSLdist', 'stdXspeed', 'stdYspeed', 'minXdist', 'minYdist', 'minAngle', 'minSLdist', 'minXspeed', 'minYspeed', \n",
    "          'maxXdist', 'maxYdist', 'maxAngle', 'maxSLdist', 'maxXspeed', 'maxYspeed', 'rangeXdist',  'rangeYdist', 'rangeAngle', \n",
    "          'rangeSLdist', 'rangeXspeed', 'rangeYspeed', 'skewXdist', 'skewYdist', 'skewAngle', 'skewSLdist', 'skewXspeed', 'skewYspeed', \n",
    "          'kurtXdist', 'kurtYdist', 'kurtAngle', 'kurtSLdist', 'kurtXspeed', 'kurtYspeed', 'cvXdist', 'cvYdist', \n",
    "          'cvAngle', 'cvSLdist', 'cvXspeed', 'cvYspeed', 'madXdist', 'madYdist', 'madAngle', 'madSLdist', 'madXspeed', 'madYspeed', \n",
    "          'action']\n",
    "\n",
    "feature_names1 = ['name', 'meanXdist', 'meanYdist', 'meanAngle', 'meanSLdist', 'meanXspeed', 'meanYspeed', 'medianXdist', \n",
    "          'medianYdist', 'medianAngle', 'medianSLdist', 'medianXspeed', 'medianYspeed', 'stdXdist', 'stdYdist', 'stdAngle', \n",
    "          'stdSLdist', 'stdXspeed', 'stdYspeed', 'minXdist', 'minYdist', 'minAngle', 'minSLdist', 'minXspeed', 'minYspeed', \n",
    "          'maxXdist', 'maxYdist', 'maxAngle', 'maxSLdist', 'maxXspeed', 'maxYspeed', 'rangeXdist',  'rangeYdist', 'rangeAngle', \n",
    "          'rangeSLdist', 'rangeXspeed', 'rangeYspeed', 'skewXdist', 'skewYdist', 'skewAngle', 'skewSLdist', 'skewXspeed', 'skewYspeed', \n",
    "          'kurtXdist', 'kurtYdist', 'kurtAngle', 'kurtSLdist', 'kurtXspeed', 'kurtYspeed', 'cvXdist', 'cvYdist', \n",
    "          'cvAngle', 'cvSLdist', 'cvXspeed', 'cvYspeed', 'madXdist', 'madYdist', 'madAngle', 'madSLdist', 'madXspeed', 'madYspeed']\n",
    "\n",
    "dir = \"c:/Users/Erika/Desktop/BnE2021/\"\n",
    "os.chdir(dir)\n",
    "data = pd.read_csv(\"Nov112021_summaryvariables.csv\", header =0, index_col=0, names = feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a vector of te hazard type before normalizing to use for labelling the clusters \n",
    "haz_type = data['hazType']\n",
    "\n",
    "\n",
    "# #Drop subject number so I can normalize\n",
    "df = data.drop(['order', 'hazType', 'action'], axis=1)\n",
    "\n",
    "df1 = preprocessing.normalize(df)\n",
    "df1 = pd.DataFrame(df1)\n",
    "data=df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Speed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-83161a007773>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Tranfer data from a panda to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Speed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sl_dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'angle'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'turn'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'signal_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stop'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'action'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Speed'"
     ]
    }
   ],
   "source": [
    "#Tranfer data from a panda to an array \n",
    "data = np.column_stack((data['Speed'], data['x_dist'], data['y_dist'], data['sl_dist'], data['angle'], data['turn'], data['signal_type'], data['stop'], data['action'], data['RT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chose 4 clusters, haven't tried to change this value. The 'Organize' function only works with 4 clusters\n",
    "\n",
    "K = 4\n",
    "j_clust = 0\n",
    "vectors = data\n",
    "\n",
    "cluster.KMeans(n_clusters=K, init='k-means++', n_init=10, max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectors is the data set, K in the number of clusters\n",
    "def clustering(vectors, K, haz_type): \n",
    "    \n",
    "    #Randomly chose 5 iterations\n",
    "    iterations = 5\n",
    "    j_clust = np.zeros((iterations))\n",
    "    \n",
    "    #Step 1: Initialize the centroid (call initial_centroid function)\n",
    "    centroids = initalize_centroid(vectors, K)\n",
    "    \n",
    "    #Step 2: Go through all data points and assign to cluster \n",
    "    vector_clusters, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3 = assign_clusters(centroids, vectors, K, haz_type)\n",
    "    \n",
    "    #Step 3: Calculate the cost function J, given the first set of centroids and labels\n",
    "    j_clust[0] = cost_function(centroids, vector_clusters, vectors, K)\n",
    "    \n",
    "    #Step 4: Repeat loop for the amount of iterations dictatcted in the assignment \n",
    "    for i in range (1, iterations): \n",
    "\n",
    "        #Step 4.1: Use the newly clustered data to calculate 'K' new centroids \n",
    "        centroids = new_centroids(vectors, vector_clusters, centroids, K)\n",
    "        \n",
    "        #Step 4.2: Go through all data points and assign to new cluster \n",
    "        vector_clusters, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3 = assign_clusters(centroids, vectors, K, haz_type)\n",
    "        \n",
    "        #Step 4.3: Calculate the cost function J, given the new set of centroids and labels\n",
    "        j_clust[i] = cost_function(centroids, vector_clusters, vectors, K)\n",
    "    \n",
    "    #Step 5: Plot how cost funtion changes through the interations \n",
    "    plot_cost_function(j_clust, iterations)\n",
    "    \n",
    "    #Step 6: Organize data\n",
    "    organize(vector_clusters, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3)\n",
    "     \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1\n",
    "def initalize_centroid(vectors,k):\n",
    "    \n",
    "    vector_length = len(vectors)\n",
    "    centroids = np.zeros((k,10))\n",
    "    \n",
    "    #Choose random data points for the initial centroids \n",
    "    for i in range (0, k):\n",
    "        random_variable = random.randrange(0, vector_length)\n",
    "        centroid = vectors[random_variable]\n",
    "        centroids[i] = centroid      \n",
    "        \n",
    "    return(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2 & 4.2\n",
    "def assign_clusters(centroids, vectors, K, haz_type):\n",
    "   \n",
    "    true_haz_in_cluster_0 = []\n",
    "    true_haz_in_cluster_1 = []\n",
    "    true_haz_in_cluster_2 = []\n",
    "    true_haz_in_cluster_3 = []\n",
    "    \n",
    "    #First column is cluster number, second is the distance from the vector to the cluster centroid\n",
    "    distances = np.zeros((K, 2))\n",
    "    #Cluster number resulting in the smallest distance between vector and current cluster centroid\n",
    "    clustered_data = np.zeros((len(vectors), 1))\n",
    " \n",
    "    #For each vector, find the closest centroid by choosing smallest euclidean distance \n",
    "    for i in range (0, len(vectors)):\n",
    "        \n",
    "        #Fill matrix with Euclidean distance to each cluster\n",
    "        for k in range (0, K):\n",
    "            distances[k,0] = k + 1\n",
    "            distances[k,1] = np.sum(np.square(vectors[i] - centroids[k]))\n",
    "        \n",
    "        #Sort data so the shortest distance appears at the top, and take the assiociated cluster number \n",
    "        sort = distances[np.argsort(distances[:,1])]\n",
    "        feature_cluster = sort[0,0]\n",
    "        clustered_data[i] = feature_cluster\n",
    "        \n",
    "        #Make 4 vectors of the known hazards to see how they are distributed within the clusters \n",
    "        if feature_cluster == 1:\n",
    "            true_haz_in_cluster_0.append(haz_type[i])\n",
    "        \n",
    "        elif feature_cluster == 2:\n",
    "            true_haz_in_cluster_1.append(haz_type[i])\n",
    "            \n",
    "        elif feature_cluster == 3:\n",
    "            true_haz_in_cluster_2.append(haz_type[i])\n",
    "        \n",
    "        elif feature_cluster == 4:\n",
    "            true_haz_in_cluster_3.append(haz_type[i])\n",
    "    \n",
    "    return clustered_data, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3 & 4.3\n",
    "def cost_function(centroids, vector_clusters, vectors, K):\n",
    "    \n",
    "    j_clust_total = 0\n",
    "    \n",
    "    for k in range (0, K):\n",
    "        j_clust = 0\n",
    "    \n",
    "        for i in range (0, len(vectors)):\n",
    "            \n",
    "            if vector_clusters[i] == k + 1:\n",
    "                j_clust = j_clust + np.sum(np.square(vectors[i] - centroids[k]))\n",
    "            \n",
    "        j_clust_total = j_clust_total + j_clust\n",
    "    \n",
    "    return j_clust_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP: 4.1\n",
    "def new_centroids(vectors, vector_clusters, centroids, K):\n",
    "   \n",
    "    total = 0\n",
    "    \n",
    "    num_vectors = np.zeros((K, 2))\n",
    "    new_centroids = np.zeros((K,10))\n",
    "    \n",
    "    #For each cluster go through all the vectors and determine if they are currently in that cluster\n",
    "    for k in range (0, K):\n",
    "        vectors_in_cluster = []\n",
    "        num_vectors[k,0] = k + 1\n",
    "        \n",
    "        for i in range (0, len(vectors)):\n",
    "\n",
    "            #If they are in that cluster, put them into a matrix \n",
    "            if vector_clusters[i] == k + 1:\n",
    "                vectors_in_cluster.append(vectors[i,:])\n",
    "                num_vectors[k,1] += 1\n",
    "        \n",
    "        #If no vectors are currently in that cluster (not probable), the centroid for the cluster is the same as before        \n",
    "        if num_vectors[k,1] == 0:\n",
    "            new_centroids[k,:] = centroids[k,:]   \n",
    "            \n",
    "        #If there are vectors in the current cluster, take average of those vectors to make new centroid vector\n",
    "        else:\n",
    "            new_centroids[k,:] = np.mean(vectors_in_cluster, axis=0)\n",
    "\n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5\n",
    "def plot_cost_function(j_clust_values, iterations):\n",
    "    \n",
    "    plt.figure(figsize=(12, 4)),\n",
    "    \n",
    "    for i in range (0, iterations):\n",
    "        plt.plot(i, j_clust_values[i], 'r.', markersize=14)\n",
    "        \n",
    "    plt.xlabel(\"Iteration Number\", fontsize=12)\n",
    "    plt.ylabel(\"Cost Value\", rotation=90, fontsize=12)\n",
    "    plt.axis([0, iterations, 0, j_clust_values[0] + 100])\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 6\n",
    "#Probably a faster anf cleaner way to do this. \n",
    "\n",
    "def organize(vector_clusters, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3):\n",
    "    \n",
    "    len1 = len(true_haz_in_cluster_0)\n",
    "    len2 = len(true_haz_in_cluster_1)\n",
    "    len3 = len(true_haz_in_cluster_2)\n",
    "    len4 = len(true_haz_in_cluster_3)\n",
    "        \n",
    "    haz1 = np.zeros((4, 1))\n",
    "    haz2 = np.zeros((4, 1))\n",
    "    haz3 = np.zeros((4, 1))\n",
    "    haz4 = np.zeros((4, 1))\n",
    "    \n",
    "    ##############CLUSTER 1#####################\n",
    "    print('The number of vectors in cluster 1 is:', len1)\n",
    "    \n",
    "    #Seperate the array of true hazard values that is associated with the cluster\n",
    "    for i in range (0, len1):\n",
    "        if true_haz_in_cluster_0[i] == 0:\n",
    "            haz1[0] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_0[i] == 1:\n",
    "            haz1[1] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_0[i] == 2:\n",
    "            haz1[2] += 1\n",
    "            \n",
    "        elif true_haz_in_cluster_0[i] == 3:\n",
    "            haz1[3] += 1\n",
    "    \n",
    "    print('There are', haz1[0], 'Instances of hazard 1')\n",
    "    print('There are', haz1[1], 'Instances of hazard 2')\n",
    "    print('There are', haz1[2], 'Instances of hazard 3')\n",
    "    print('There are', haz1[3], 'Instances of hazard 4')\n",
    "    \n",
    "    sort1 = haz1.argsort(axis=0)\n",
    "    highest_haz1 = sort1[3] + 1\n",
    "    print('The most common hazard in cluster 1 is:', highest_haz1, '\\n')\n",
    "    \n",
    "    ###############Cluster 2####################\n",
    "    print('The number of vectors in cluster 2 is:', len2)\n",
    "    \n",
    "    for i in range (0, len2):\n",
    "        if true_haz_in_cluster_1[i] == 0:\n",
    "            haz2[0] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_1[i] == 1:\n",
    "            haz2[1] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_1[i] == 2:\n",
    "            haz2[2] += 1\n",
    "            \n",
    "        elif true_haz_in_cluster_1[i] == 3:\n",
    "            haz2[3] += 1\n",
    "    \n",
    "    print('There are', haz2[0], 'Instances of hazard 1')\n",
    "    print('There are', haz2[1], 'Instances of hazard 2')\n",
    "    print('There are', haz2[2], 'Instances of hazard 3')\n",
    "    print('There are', haz2[3], 'Instances of hazard 4')\n",
    "    \n",
    "    sort2 = haz2.argsort(axis=0)\n",
    "    highest_haz2 = sort2[3] + 1\n",
    "    \n",
    "    print('The most common hazard in cluster 2 is:', highest_haz2, '\\n')\n",
    "    \n",
    "    ############ Cluster 3 ######################\n",
    "    print('The number of vectors in cluster 3 is:', len3)\n",
    "    \n",
    "    for i in range (0, len3):\n",
    "        if true_haz_in_cluster_2[i] == 0:\n",
    "            haz3[0] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_2[i] == 1:\n",
    "            haz3[1] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_2[i] == 2:\n",
    "            haz3[2] += 1\n",
    "            \n",
    "        elif true_haz_in_cluster_2[i] == 3:\n",
    "            haz3[3] += 1\n",
    "    \n",
    "    print('There are', haz3[0], 'Instances of hazard 1')\n",
    "    print('There are', haz3[1], 'Instances of hazard 2')\n",
    "    print('There are', haz3[2], 'Instances of hazard 3')\n",
    "    print('There are', haz3[3], 'Instances of hazard 4')\n",
    "    \n",
    "    sort3 = haz3.argsort(axis=0)\n",
    "    highest_haz3 = sort3[3] + 1\n",
    "    print('The most common hazard in cluster 3 is:', highest_haz3, '\\n')\n",
    "    \n",
    "    ###########Cluster 4#######################\n",
    "    print('The number of vectors in cluster 4 is:', len4)\n",
    "    \n",
    "    for i in range (0, len4):\n",
    "        if true_haz_in_cluster_3[i] == 0:\n",
    "            haz4[0] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_3[i] == 1:\n",
    "            haz4[1] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_3[i] == 2:\n",
    "            haz4[2] += 1\n",
    "            \n",
    "        elif true_haz_in_cluster_3[i] == 3:\n",
    "            haz4[3] += 1\n",
    "    \n",
    "    print('There are', haz4[0], 'Instances of hazard 1')\n",
    "    print('There are', haz4[1], 'Instances of hazard 2')\n",
    "    print('There are', haz4[2], 'Instances of hazard 3')\n",
    "    print('There are', haz4[3], 'Instances of hazard 4')\n",
    "    \n",
    "    sort4 = haz4.argsort(axis=0)\n",
    "    highest_haz4 = sort4[3] + 1\n",
    "    print('The most common hazard in cluster 4 is:', highest_haz4)\n",
    "        \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    \n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
