{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import time\n",
    "import sklearn\n",
    "from sklearn import preprocessing, cluster\n",
    "import os\n",
    "# import cv2\n",
    "\n",
    "feature_names = ['name', 'order', 'hazType', 'meanXdist', 'meanYdist', 'meanAngle', 'meanSLdist', 'meanXspeed', 'meanYspeed', 'medianXdist', \n",
    "          'medianYdist', 'medianAngle', 'medianSLdist', 'medianXspeed', 'medianYspeed', 'stdXdist', 'stdYdist', 'stdAngle', \n",
    "          'stdSLdist', 'stdXspeed', 'stdYspeed', 'minXdist', 'minYdist', 'minAngle', 'minSLdist', 'minXspeed', 'minYspeed', \n",
    "          'maxXdist', 'maxYdist', 'maxAngle', 'maxSLdist', 'maxXspeed', 'maxYspeed', 'rangeXdist',  'rangeYdist', 'rangeAngle', \n",
    "          'rangeSLdist', 'rangeXspeed', 'rangeYspeed', 'skewXdist', 'skewYdist', 'skewAngle', 'skewSLdist', 'skewXspeed', 'skewYspeed', \n",
    "          'kurtXdist', 'kurtYdist', 'kurtAngle', 'kurtSLdist', 'kurtXspeed', 'kurtYspeed', 'cvXdist', 'cvYdist', \n",
    "          'cvAngle', 'cvSLdist', 'cvXspeed', 'cvYspeed', 'madXdist', 'madYdist', 'madAngle', 'madSLdist', 'madXspeed', 'madYspeed', \n",
    "          'action']\n",
    "\n",
    "feature_names1 = ['name', 'meanXdist', 'meanYdist', 'meanAngle', 'meanSLdist', 'meanXspeed', 'meanYspeed', 'medianXdist', \n",
    "          'medianYdist', 'medianAngle', 'medianSLdist', 'medianXspeed', 'medianYspeed', 'stdXdist', 'stdYdist', 'stdAngle', \n",
    "          'stdSLdist', 'stdXspeed', 'stdYspeed', 'minXdist', 'minYdist', 'minAngle', 'minSLdist', 'minXspeed', 'minYspeed', \n",
    "          'maxXdist', 'maxYdist', 'maxAngle', 'maxSLdist', 'maxXspeed', 'maxYspeed', 'rangeXdist',  'rangeYdist', 'rangeAngle', \n",
    "          'rangeSLdist', 'rangeXspeed', 'rangeYspeed', 'skewXdist', 'skewYdist', 'skewAngle', 'skewSLdist', 'skewXspeed', 'skewYspeed', \n",
    "          'kurtXdist', 'kurtYdist', 'kurtAngle', 'kurtSLdist', 'kurtXspeed', 'kurtYspeed', 'cvXdist', 'cvYdist', \n",
    "          'cvAngle', 'cvSLdist', 'cvXspeed', 'cvYspeed', 'madXdist', 'madYdist', 'madAngle', 'madSLdist', 'madXspeed', 'madYspeed']\n",
    "\n",
    "dir = \"c:/Users/Erika/Desktop/BnE2021/\"\n",
    "os.chdir(dir)\n",
    "data = pd.read_csv(\"Nov112021_summaryvariables.csv\", header =0, index_col=0, names = feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a vector of te hazard type before normalizing to use for labelling the clusters \n",
    "haz_type = data['hazType']\n",
    "\n",
    "\n",
    "# #Drop subject number so I can normalize\n",
    "df = data.drop(['order', 'hazType', 'action'], axis=1)\n",
    "\n",
    "df1 = preprocessing.normalize(df)\n",
    "df1 = pd.DataFrame(df1)\n",
    "data = df1.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._maybe_get_bool_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._unpack_bool_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ba04bc9f319d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mclustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhaz_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-means++'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f2954f64d214>\u001b[0m in \u001b[0;36mclustering\u001b[1;34m(vectors, K, haz_type)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#Step 2: Go through all data points and assign to cluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mvector_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_haz_in_cluster_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_haz_in_cluster_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_haz_in_cluster_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_haz_in_cluster_3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_clusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhaz_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m#Step 3: Calculate the cost function J, given the first set of centroids and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-387b741c2361>\u001b[0m in \u001b[0;36massign_clusters\u001b[1;34m(centroids, vectors, K, haz_type)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mfeature_cluster\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mtrue_haz_in_cluster_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhaz_type\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mfeature_cluster\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#Chose 4 clusters, haven't tried to change this value. The 'Organize' function only works with 4 clusters\n",
    "\n",
    "K = 4\n",
    "j_clust = 0\n",
    "vectors = data\n",
    "\n",
    "clustering(vectors, K, haz_type)\n",
    "\n",
    "cluster.KMeans(n_clusters=K, init='k-means++', n_init=10, max_iter=300, tol=0.0001, verbose=0, random_state=None, copy_x=True, algorithm='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectors is the data set, K in the number of clusters\n",
    "def clustering(vectors, K, haz_type): \n",
    "    \n",
    "    #Randomly chose 5 iterations\n",
    "    iterations = 5\n",
    "    j_clust = np.zeros((iterations))\n",
    "    \n",
    "    #Step 1: Initialize the centroid (call initial_centroid function)\n",
    "    centroids = initalize_centroid(vectors, K)\n",
    "    \n",
    "    #Step 2: Go through all data points and assign to cluster \n",
    "    vector_clusters, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3 = assign_clusters(centroids, vectors, K, haz_type)\n",
    "    \n",
    "    #Step 3: Calculate the cost function J, given the first set of centroids and labels\n",
    "    j_clust[0] = cost_function(centroids, vector_clusters, vectors, K)\n",
    "    \n",
    "    #Step 4: Repeat loop for the amount of iterations dictatcted in the assignment \n",
    "    for i in range (1, iterations): \n",
    "\n",
    "        #Step 4.1: Use the newly clustered data to calculate 'K' new centroids \n",
    "        centroids = new_centroids(vectors, vector_clusters, centroids, K)\n",
    "        \n",
    "        #Step 4.2: Go through all data points and assign to new cluster \n",
    "        vector_clusters, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3 = assign_clusters(centroids, vectors, K, haz_type)\n",
    "        \n",
    "        #Step 4.3: Calculate the cost function J, given the new set of centroids and labels\n",
    "        j_clust[i] = cost_function(centroids, vector_clusters, vectors, K)\n",
    "    \n",
    "    #Step 5: Plot how cost funtion changes through the interations \n",
    "    plot_cost_function(j_clust, iterations)\n",
    "    \n",
    "    #Step 6: Organize data\n",
    "    organize(vector_clusters, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3)\n",
    "     \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1\n",
    "def initalize_centroid(vectors,k):\n",
    "    \n",
    "    vector_length = len(vectors)\n",
    "    centroids = np.zeros((k,60))\n",
    "    \n",
    "    #Choose random data points for the initial centroids \n",
    "    for i in range (0, k):\n",
    "        random_variable = random.randrange(0, vector_length)\n",
    "        centroid = vectors[random_variable]\n",
    "        centroids[i] = centroid      \n",
    "        \n",
    "    return(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2 & 4.2\n",
    "def assign_clusters(centroids, vectors, K, haz_type):\n",
    "   \n",
    "    true_haz_in_cluster_0 = []\n",
    "    true_haz_in_cluster_1 = []\n",
    "    true_haz_in_cluster_2 = []\n",
    "    true_haz_in_cluster_3 = []\n",
    "    \n",
    "    #First column is cluster number, second is the distance from the vector to the cluster centroid\n",
    "    distances = np.zeros((K, 2))\n",
    "    #Cluster number resulting in the smallest distance between vector and current cluster centroid\n",
    "    clustered_data = np.zeros((len(vectors), 1))\n",
    " \n",
    "    #For each vector, find the closest centroid by choosing smallest euclidean distance \n",
    "    for i in range (0, len(vectors)):\n",
    "        \n",
    "        #Fill matrix with Euclidean distance to each cluster\n",
    "        for k in range (0, K):\n",
    "            distances[k,0] = k + 1\n",
    "            distances[k,1] = np.sum(np.square(vectors[i] - centroids[k]))\n",
    "        \n",
    "        #Sort data so the shortest distance appears at the top, and take the assiociated cluster number \n",
    "        sort = distances[np.argsort(distances[:,1])]\n",
    "        feature_cluster = sort[0,0]\n",
    "        clustered_data[i] = feature_cluster\n",
    "        \n",
    "        #Make 4 vectors of the known hazards to see how they are distributed within the clusters \n",
    "        if feature_cluster == 1:\n",
    "            true_haz_in_cluster_0.append(haz_type[i])\n",
    "        \n",
    "        elif feature_cluster == 2:\n",
    "            true_haz_in_cluster_1.append(haz_type[i])\n",
    "            \n",
    "        elif feature_cluster == 3:\n",
    "            true_haz_in_cluster_2.append(haz_type[i])\n",
    "        \n",
    "        elif feature_cluster == 4:\n",
    "            true_haz_in_cluster_3.append(haz_type[i])\n",
    "    \n",
    "    return clustered_data, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3 & 4.3\n",
    "def cost_function(centroids, vector_clusters, vectors, K):\n",
    "    \n",
    "    j_clust_total = 0\n",
    "    \n",
    "    for k in range (0, K):\n",
    "        j_clust = 0\n",
    "    \n",
    "        for i in range (0, len(vectors)):\n",
    "            \n",
    "            if vector_clusters[i] == k + 1:\n",
    "                j_clust = j_clust + np.sum(np.square(vectors[i] - centroids[k]))\n",
    "            \n",
    "        j_clust_total = j_clust_total + j_clust\n",
    "    \n",
    "    return j_clust_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP: 4.1\n",
    "def new_centroids(vectors, vector_clusters, centroids, K):\n",
    "   \n",
    "    total = 0\n",
    "    \n",
    "    num_vectors = np.zeros((K, 2))\n",
    "    new_centroids = np.zeros((K,10))\n",
    "    \n",
    "    #For each cluster go through all the vectors and determine if they are currently in that cluster\n",
    "    for k in range (0, K):\n",
    "        vectors_in_cluster = []\n",
    "        num_vectors[k,0] = k + 1\n",
    "        \n",
    "        for i in range (0, len(vectors)):\n",
    "\n",
    "            #If they are in that cluster, put them into a matrix \n",
    "            if vector_clusters[i] == k + 1:\n",
    "                vectors_in_cluster.append(vectors[i,:])\n",
    "                num_vectors[k,1] += 1\n",
    "        \n",
    "        #If no vectors are currently in that cluster (not probable), the centroid for the cluster is the same as before        \n",
    "        if num_vectors[k,1] == 0:\n",
    "            new_centroids[k,:] = centroids[k,:]   \n",
    "            \n",
    "        #If there are vectors in the current cluster, take average of those vectors to make new centroid vector\n",
    "        else:\n",
    "            new_centroids[k,:] = np.mean(vectors_in_cluster, axis=0)\n",
    "\n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5\n",
    "def plot_cost_function(j_clust_values, iterations):\n",
    "    \n",
    "    plt.figure(figsize=(12, 4)),\n",
    "    \n",
    "    for i in range (0, iterations):\n",
    "        plt.plot(i, j_clust_values[i], 'r.', markersize=14)\n",
    "        \n",
    "    plt.xlabel(\"Iteration Number\", fontsize=12)\n",
    "    plt.ylabel(\"Cost Value\", rotation=90, fontsize=12)\n",
    "    plt.axis([0, iterations, 0, j_clust_values[0] + 100])\n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 6\n",
    "#Probably a faster anf cleaner way to do this. \n",
    "\n",
    "def organize(vector_clusters, true_haz_in_cluster_0, true_haz_in_cluster_1, true_haz_in_cluster_2, true_haz_in_cluster_3):\n",
    "    \n",
    "    len1 = len(true_haz_in_cluster_0)\n",
    "    len2 = len(true_haz_in_cluster_1)\n",
    "    len3 = len(true_haz_in_cluster_2)\n",
    "    len4 = len(true_haz_in_cluster_3)\n",
    "        \n",
    "    haz1 = np.zeros((4, 1))\n",
    "    haz2 = np.zeros((4, 1))\n",
    "    haz3 = np.zeros((4, 1))\n",
    "    haz4 = np.zeros((4, 1))\n",
    "    \n",
    "    ##############CLUSTER 1#####################\n",
    "    print('The number of vectors in cluster 1 is:', len1)\n",
    "    \n",
    "    #Seperate the array of true hazard values that is associated with the cluster\n",
    "    for i in range (0, len1):\n",
    "        if true_haz_in_cluster_0[i] == 0:\n",
    "            haz1[0] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_0[i] == 1:\n",
    "            haz1[1] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_0[i] == 2:\n",
    "            haz1[2] += 1\n",
    "            \n",
    "        elif true_haz_in_cluster_0[i] == 3:\n",
    "            haz1[3] += 1\n",
    "    \n",
    "    print('There are', haz1[0], 'Instances of hazard 1')\n",
    "    print('There are', haz1[1], 'Instances of hazard 2')\n",
    "    print('There are', haz1[2], 'Instances of hazard 3')\n",
    "    print('There are', haz1[3], 'Instances of hazard 4')\n",
    "    \n",
    "    sort1 = haz1.argsort(axis=0)\n",
    "    highest_haz1 = sort1[3] + 1\n",
    "    print('The most common hazard in cluster 1 is:', highest_haz1, '\\n')\n",
    "    \n",
    "    ###############Cluster 2####################\n",
    "    print('The number of vectors in cluster 2 is:', len2)\n",
    "    \n",
    "    for i in range (0, len2):\n",
    "        if true_haz_in_cluster_1[i] == 0:\n",
    "            haz2[0] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_1[i] == 1:\n",
    "            haz2[1] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_1[i] == 2:\n",
    "            haz2[2] += 1\n",
    "            \n",
    "        elif true_haz_in_cluster_1[i] == 3:\n",
    "            haz2[3] += 1\n",
    "    \n",
    "    print('There are', haz2[0], 'Instances of hazard 1')\n",
    "    print('There are', haz2[1], 'Instances of hazard 2')\n",
    "    print('There are', haz2[2], 'Instances of hazard 3')\n",
    "    print('There are', haz2[3], 'Instances of hazard 4')\n",
    "    \n",
    "    sort2 = haz2.argsort(axis=0)\n",
    "    highest_haz2 = sort2[3] + 1\n",
    "    \n",
    "    print('The most common hazard in cluster 2 is:', highest_haz2, '\\n')\n",
    "    \n",
    "    ############ Cluster 3 ######################\n",
    "    print('The number of vectors in cluster 3 is:', len3)\n",
    "    \n",
    "    for i in range (0, len3):\n",
    "        if true_haz_in_cluster_2[i] == 0:\n",
    "            haz3[0] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_2[i] == 1:\n",
    "            haz3[1] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_2[i] == 2:\n",
    "            haz3[2] += 1\n",
    "            \n",
    "        elif true_haz_in_cluster_2[i] == 3:\n",
    "            haz3[3] += 1\n",
    "    \n",
    "    print('There are', haz3[0], 'Instances of hazard 1')\n",
    "    print('There are', haz3[1], 'Instances of hazard 2')\n",
    "    print('There are', haz3[2], 'Instances of hazard 3')\n",
    "    print('There are', haz3[3], 'Instances of hazard 4')\n",
    "    \n",
    "    sort3 = haz3.argsort(axis=0)\n",
    "    highest_haz3 = sort3[3] + 1\n",
    "    print('The most common hazard in cluster 3 is:', highest_haz3, '\\n')\n",
    "    \n",
    "    ###########Cluster 4#######################\n",
    "    print('The number of vectors in cluster 4 is:', len4)\n",
    "    \n",
    "    for i in range (0, len4):\n",
    "        if true_haz_in_cluster_3[i] == 0:\n",
    "            haz4[0] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_3[i] == 1:\n",
    "            haz4[1] += 1\n",
    "        \n",
    "        elif true_haz_in_cluster_3[i] == 2:\n",
    "            haz4[2] += 1\n",
    "            \n",
    "        elif true_haz_in_cluster_3[i] == 3:\n",
    "            haz4[3] += 1\n",
    "    \n",
    "    print('There are', haz4[0], 'Instances of hazard 1')\n",
    "    print('There are', haz4[1], 'Instances of hazard 2')\n",
    "    print('There are', haz4[2], 'Instances of hazard 3')\n",
    "    print('There are', haz4[3], 'Instances of hazard 4')\n",
    "    \n",
    "    sort4 = haz4.argsort(axis=0)\n",
    "    highest_haz4 = sort4[3] + 1\n",
    "    print('The most common hazard in cluster 4 is:', highest_haz4)\n",
    "        \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    \n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
